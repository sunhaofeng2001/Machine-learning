第1章  绪 论
=========
#### 1.1 引言
机器学习致力于研究如何通过计算的手段，利用经
验来改善系统自身的性能.在计算机系统中，“经验”通常以“数据”形式存
在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模
型（model）的算法，即"学习算法（learning algorithm）。  
本书用“模型"泛指从数据中学得的结果.有文献用“模型”指全局性结
果（例如一棵决策树），而用‘模式’指局部性结果（例如一条规则）。
#### 1.2 基本术语
记录数据的集合称为一个“数据集” (data set),其中每条记录是关于一
个事件或对象的描述，称为一个“示例” (instance)或“样
本” (sample).反映事件或对象在某方面的表现或性质的事项，称为“属性” (attribute)或“特征” (feature);属性上的取
值，称为“属性值” (attribute value).属性张成的空
间称为“属性空间"(attribute space)、"样本空间"(sample space)或“输入
空间”.由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个
"特征向量"(feature vector).  

一般地，令D ={x1,x2,x3,x4,……,xm} 表示包含m个示例的数据集，每个
示例由d个属性描述(例如上面的西瓜数据使用了 3个属性)，则每个示例
xi = {xi1,xi2,xi3……,xid}是d维样本空间中的一个向量，其中xij是
此在第j个属性上的取值, d称为样本xi的"维数"(dimensionality).  

从数据中学得模型的过程称为“学习” (learning)或“训练”(成ining),
这个过程通过执行某个学习算法来完成.训练过程中使用的数据称为“训练
数据” (training data),其中每个样本称为一个“训练样本(training sample)5
训练样本组成的集合称为“训练集” (training set).学得模型对应了关于数据
的某种潜在的规律，因此亦称“假设” (hypothesis);这种潜在规律自身，则称
为“真相”或“真实"(ground-truth),学习过程就是为了找出或逼近真相.本
书有时将模型称为“学习器” (learner),可看作学习算法在给定数据和参数空
间上的实例化.  

分类和预测。  

学得模型后，使用其进行预测的过程称为“测试” (testing),被预测的样本
称为“测试样本” (testing sample).例如在学得f后，对测试例缶，可得到其预
测标记y = f(x).  

根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：“监督
学习” (supervised learning)和“无监督学习”(unsupervised learning),分类
和回归是前者的代表，而聚类则是后者的代表.   

学得模型适用于
新样本的能力，称为“泛化” (generalization).具有强泛化能力的模型能
很好地适用于整个样本空间.  

通常假设样本空间中全
体样本服从一个未知“分布”(distribution) D 我们获得的每个样本都是独立
地从这个分布上采样获得的，即"独立同分布"(independent and identically
distributed). 一般而言，训练样本越多，我们得到的关于D 的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型.  
#### 1.3 假设空间
归纳(induction)与演绎(deduction)是科学推理的两大基本手段.前者是从
特殊到一般的“泛化"(generalization)过程，即从具体的事实归结出一般性规
律；后者则是从一般到特殊的“特化” (specialization)过程，即从基础原理推演
出具体状况.例如，在数学公理系统中，基于一组公理和推理规则推导出与之
相洽的定理，这是演绎;而“从样例中学习”显然是一个归纳的过程，因此亦称
"归纳学习”(inductive learning).  

归纳学习有狭义与广义之分，广义的归纳学习大体相当于从样例中学习,
而狭义的归纳学习则要求从训练数据中学得概念(concept),因此亦称为“概念
学习”或“概念形成”.  
#### 1.4 归纳偏好
通过学习得到的模型对应了假设空间中的一个假设.机器学习
算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias）,
或简称为“偏好”.  

任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看
似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果.  

这里的每个训
练样本是图中的一个点 （x , y）.要学得一个与训练集一致的模型，相当于找到一
条穿过所有训练样本点的曲线.显然，对有限个样本点组成的训练集，存在着
很多条曲线与其一致.我们的学习算法必须有某种偏好，才能产出它认为“正
确”的模型.   
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-23%20202235.png)  
归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进
行选择的启发式或“价值观”.那么，有没有一般性的原则来引导算法确立
“正确的”偏好呢？ “奥卡姆剃刀”（Occanfs razoT）是一种常用的、自然科学
研究中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个” .  

脱离具体问题，空
泛地谈论“什么学习算法更好"毫无意义，因为若考虑所有潜在的问题，则所
有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题；在
某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法
自身的归纳偏好与问题是否相配,往往会起到决定性的作用.
