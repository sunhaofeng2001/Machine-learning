第6章 支持向量机
========
#### 6.1 间隔与支持向量
给定训练样本集 D= {(x1,y1),(x2,y2),……,(xm,ym)},yi={-1,+1}.分
类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面，将
不同类别的样本分开.  
直观上看，应该去找位于两类训练样本“正中间”的划分超平面,但是由于训练集的局限性或噪声的因素，训练集外的样本可能比图6.1中的训练
样本更接近两个类的分隔界，这将使许多划分超平面出现错误，而红色的超平
面受影响最小.换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见
示例的泛化能力最强.  
在样本空间中，划分超平面可通过如下线性方程来描述:  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20215300.png)  
其中M = (w1；w2;...;wd)为法向量，决定了超平面的方向；b为位移项，决定
了超平面与原点之间的距离.显然，划分超平面可被法向量w和位移b确定,下面我们将其记为(w,b).样本空间中任意点。到超平面(w,b)的距离可写为  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20215416.png)  
假设超平面(w.b)能将训练样本正确分类，即对于(xi,yi)£ D,若yi=
+1,则有 wTxi + b〉0;若yi=一1,则有 wTxi + b <0.令  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20215605.png)  
距离超平面最近的这几个训练样本点使式(6.3)的等号成立,
它们被称为“支持向量” (support vector),两个异类支持向量到超平面的距离
之和为  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20220057.png)  
它被称为“间隔” (margin).  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20220131.png)  
欲找到具有“最大间隔”(maximum margin)的划分超平面，也就是要找
到能满足式(6.3)中约束的参数w和饥使得7最大，即  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20220158.png)  
显然，为了最大化间隔，仅需最大化iiwr\这等价于最小化iiwii2.于是,
式(6.5)可重写为  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20220215.png)  
这就是支持向量机(Support Vector Machine,简称SVM)的基本型.
#### 6.2 对偶问题
我们希望求解式(6.6)来得到大间隔划分超平面所对应的模型  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20220215.png)  
其中s和b是模型参数. 
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20222511.png)  
SMO的基本思路是先固定ai之外的所有参数，然后求ai上的极值.由于
存在约束E ai* yi=0,若固定之外的其他变量，则叫可由其他变量导出.
于是，SMO每次选择两个变量ai和aj,并固定其他参数.这样，在参数初始化
后，SMO不断执行如下两个步骤直至收敛:  
选取一对需更新的变量ai和aj;  
固定ai和aj以外的参数，求解下式获得更新后的ai和aj.  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20223741.png)  
#### 6.3 核函数
训练样本是线性可分的，即存在一个划分
超平面能将训练样本正确分类.然而在现实任务中，原始样本空间内也许并不
存在一个能正确划分两类样本的超平面.  
![image](https://github.com/sunhaofeng2001/Machine-learning/blob/master/IMG/%E6%89%B9%E6%B3%A8%202020-08-24%20224449.png)  
对这样的问题，可将样本从原始空间映射到一个更高维的特征空间，使得
样本在这个特征空间内线性可分.例如在图6.3中，若将原始的二维空间映射
到一个合适的三维空间，就能找到一个合适的划分超平面.幸运的是，如果原始
空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分.
